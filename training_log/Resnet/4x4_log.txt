一般訓練，採隨機方法
1~5: args_Res = {
    'num_of_generate_data_for_train': 1024,
    'epochs': 50,
    'batch_size': batch_size,
    'verbose': True,
    'type': 0,
    'train': True,
    'load_model_name': None
}

打開greedy測試
6~19: args_Res = {
    'num_of_generate_data_for_train': 1024,
    'epochs': 50,
    'batch_size': batch_size,
    'verbose': True,
    'type': 0,
    'train': True,
    'load_model_name': None
}
訓練結果十分良好，有記住greedy的策略，並且穩贏random，但有點練太多greedy導致overfitting
測試後大約在ver17對greedy的勝率最高

從ver17訓練，關閉greedy使其自行對下學習
20~30: : args_Res = {
    'num_of_generate_data_for_train': 1024,
    'epochs': 50,
    'batch_size': batch_size,
    'verbose': True,
    'type': 0,
    'train': True,
    'load_model_name': None
}
自行對下反而結果稍遜，推測是自行對弈時理解錯誤策略，回退ver17繼續訓練


修改程式，使其與ver17產生對練資料，從ver17開始訓練
31~39 : args_Res = {
    'num_of_generate_data_for_train': 1024,
    'epochs': 50,
    'batch_size': batch_size,
    'verbose': True,
    'type': 0,
    'train': True,
    'load_model_name': None
}
結果普通，並沒進步多少反而些許退步

打開greedy訓練，並且訓練對象改回自己
40~41: args_Res = {
    'num_of_generate_data_for_train': 1024,
    'epochs': 50,
    'batch_size': batch_size,
    'verbose': True,
    'type': 0,
    'train': True,
    'load_model_name': None
}
結果還不錯，對抗random穩贏，但打greedy勝率大概維持在75左右

改用自身模型對抗ver41+greedy對練
42~53 :args_Res = {
    'num_of_generate_data_for_train': 1024,
    'epochs': 50,
    'batch_size': batch_size,
    'verbose': True,
    'type': 0,
    'train': True,
    'load_model_name': None
}
經測試大約在ver50對greedy勝率最高(85%)，其餘效能起伏不定，時好時壞

以ver50模型訓練，欲訓練模型採最大預測，對手採自身但隨機取2
54 :args_Res = {
    'num_of_generate_data_for_train': 1024,
    'epochs': 50,
    'batch_size': batch_size,
    'verbose': True,
    'type': 0,
    'train': True,
    'load_model_name': None
}
所有模型經測試後為ver41勝率最高(77%)

發現遊戲程式的history資料錯誤(已修正)，回退以ver41模型訓練，策略同樣採用對手為同模型+greedy，本身採模型預測最大值
55~69: args_Res = {
    'num_of_generate_data_for_train': 1024,
    'epochs': 50,
    'batch_size': batch_size,
    'verbose': True,
    'type': 0,
    'train': True,
    'load_model_name': None
}
沒什麼進步，重新從ver0練看看

從ver0訓練
70~77: args_Res = {
    'num_of_generate_data_for_train': 1024,
    'epochs': 50,
    'batch_size': batch_size,
    'verbose': True,
    'type': 0,
    'train': True,
    'load_model_name': None
}
測試後對greedy時戰績不錯，但作為先手時輸的機率很高，故改成自身greedy vs 自身max

改成自身greedy vs 自身max
78~79: args_Res = {
    'num_of_generate_data_for_train': 1024,
    'epochs': 50,
    'batch_size': batch_size,
    'verbose': True,
    'type': 0,
    'train': True,
    'load_model_name': None
}
並沒有特別有起色
