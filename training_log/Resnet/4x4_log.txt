一般訓練，採隨機方法
1~5: args_Res = {
    'num_of_generate_data_for_train': 1024,
    'epochs': 50,
    'batch_size': batch_size,
    'verbose': True,
    'type': 0,
    'train': True,
    'load_model_name': None
}

打開greedy測試
6~19: args_Res = {
    'num_of_generate_data_for_train': 1024,
    'epochs': 50,
    'batch_size': batch_size,
    'verbose': True,
    'type': 0,
    'train': True,
    'load_model_name': None
}
訓練結果十分良好，有記住greedy的策略，並且穩贏random，但有點練太多greedy導致overfitting
測試後大約在ver17對greedy的勝率最高

從ver17訓練，關閉greedy使其自行對下學習
20~30: : args_Res = {
    'num_of_generate_data_for_train': 1024,
    'epochs': 50,
    'batch_size': batch_size,
    'verbose': True,
    'type': 0,
    'train': True,
    'load_model_name': None
}
自行對下反而結果稍遜，推測是自行對弈時理解錯誤策略，回退ver17繼續訓練


修改程式，使其與ver17產生對練資料，從ver17開始訓練
31~ : args_Res = {
    'num_of_generate_data_for_train': 1024,
    'epochs': 50,
    'batch_size': batch_size,
    'verbose': True,
    'type': 0,
    'train': True,
    'load_model_name': None
}